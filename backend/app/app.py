import os
import shutil
import glob
import numpy as np
import joblib
import torch
import torchaudio
import faiss
import librosa
import json
import time  
import asyncio
# ì¶”ê°€ ë³¸ ###################
import soundfile as sf
from pydub import AudioSegment
#########################
from fastapi import FastAPI, UploadFile, File, HTTPException,Form, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.concurrency import run_in_threadpool
from speechbrain.inference import EncoderClassifier
from torchaudio.transforms import Resample
import matplotlib
# macOSì—ì„œ GUI ë°±ì—”ë“œê°€ ì“°ì—¬ì„œ ë°œìƒí•˜ëŠ” ì—ëŸ¬ ë°©ì§€: ë°˜ë“œì‹œ pyplot ì´ì „ì— backend ì„¤ì •
matplotlib.use("Agg")   # non-GUI backend (íŒŒì¼ë¡œ ì €ì¥ ì „ìš©)
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter
from fastapi.staticfiles import StaticFiles # <-- ì¶”ê°€

# --- 1. FastAPI ì•± ë° ëª¨ë¸ ë¡œë”© ---
app = FastAPI()

# [ì¶”ê°€] ì •ì  íŒŒì¼ ê²½ë¡œ ì„¤ì •
# 'backend/static/graphs' í´ë”ì— ì €ì¥ëœ íŒŒì¼ì„ 'http://ì„œë²„ì£¼ì†Œ/static/graphs/íŒŒì¼ì´ë¦„'ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê²Œ í•¨
APP_DIR = os.path.dirname(os.path.abspath(__file__))
BACKEND_DIR = os.path.dirname(APP_DIR)
MODELS_DIR = os.path.join(BACKEND_DIR, 'models')
DATA_DIR = os.path.join(BACKEND_DIR, 'data')

# --- ì•ˆì „í•œ ì •ì  íŒŒì¼ ê²½ë¡œ ì¬ì„¤ì • (ì ˆëŒ€ê²½ë¡œ) ---
STATIC_DIR = os.path.join(BACKEND_DIR, "static")
GRAPHS_DIR = os.path.join(STATIC_DIR, "graphs")
os.makedirs(GRAPHS_DIR, exist_ok=True)
# mount StaticFiles with absolute path (ë®ì–´ì“°ê¸° í—ˆìš©)
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
USER_TO_GTZAN_MAP = {
    "ë°œë¼ë“œ": ["pop", "classical", "jazz", "blues", "k-ballad"], 
    "ëŒ„ìŠ¤": ["disco", "pop", "hiphop", "k-pop", "dance-pop"], 
    "R&B": ["hiphop", "jazz", "pop", "r&b", "soul"],
    "ë¡": ["rock", "metal", "k-rock"],
    "ë©/í™í•©": ["hiphop", "rap", "k-rap"],
    "íŒ": ["pop", "disco", "k-pop"]
}

# ëª¨ë¸ ë¡œë“œ [spkrec-ecapa-voxceleb] ECAPA ì‚¬ìš©
model = EncoderClassifier.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    run_opts={"device":"cuda" if torch.cuda.is_available() else "cpu"}
# ì €ì¥ dir ì§€ìš¸ ê°€ëŠ¥ì„± ìˆìŒ
)

try:
    print("ëª¨ë¸/ë°ì´í„° ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    classifier = EncoderClassifier.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb",
        run_opts={"device":"cuda" if torch.cuda.is_available() else "cpu"}
    )    
        
    singer_index = faiss.read_index(os.path.join(MODELS_DIR, "singers.index"))
    singer_id_map = joblib.load(os.path.join(MODELS_DIR, "singer_id_map.pkl"))
    
    with open(os.path.join(DATA_DIR, "songs_db.json"), 'r', encoding='utf-8') as f:
        songs_db = json.load(f)
        
    with open(os.path.join(DATA_DIR, "singer_info.json"), 'r', encoding='utf-8') as f:
        singer_info = json.load(f)
    
    print("ëª¨ë“  ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
except Exception as e:
    print(f"ëª¨ë¸/ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    classifier, singer_index, singer_id_map, songs_db = None, None, None, None

# --- 2. í•µì‹¬ ë¶„ì„ í•¨ìˆ˜ë“¤ ---
from pydub import AudioSegment

def convert_to_wav(aac_path, wav_file_path):
    audio = AudioSegment.from_file(aac_path, format="aac")
    audio = audio.set_frame_rate(16000).set_channels(1)
    audio.export(wav_file_path, format="wav")
    return wav_file_path




# ë…¹ìŒ íŒŒì¼ ì•ˆì „í•˜ê²Œ ë¡œë”©ë˜ê²Œ 
def safe_load_audio(file_path, target_sr=16000, mono=True):
    try:
        # librosaê°€ wav í—¤ë” ê¹¨ì§„ ê²ƒë„ ìë™ ë³µì›
        y, sr = librosa.load(file_path, sr=target_sr) # mono=True
        # ë¬´ìŒ ë°©ì§€ìš© ì•„ì£¼ ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
        if np.max(np.abs(y)) < 1e-5:
            y = y + np.random.randn(len(y)) * 1e-5
        return y, target_sr
    except Exception as e:
        print(f"[Audio Load Error] {e}")
        data, sr = sf.read(file_path)
        return data.astype(np.float32), sr



def extract_xvector(file_path):
    signal, sr = sf.read(file_path)
    # ìµœì†Œ ê¸¸ì´ ì²´í¬
    if len(signal) < sr * 0.5:  # 0.5ì´ˆ ë¯¸ë§Œ
        raise ValueError("Audio too short for x-vector extraction")
    return classifier.encode_file(file_path)


def get_xvector(file_path, model):
    TARGET_SR = 16000
    MIN_LENGTH_SEC = 0.5
    try:
        signal, fs = torchaudio.load(file_path)
        if signal.shape[0] > 1:
            signal = torch.mean(signal, dim=0, keepdim=True)
        if fs != TARGET_SR:
            resampler = Resample(orig_freq=fs, new_freq=TARGET_SR)
            signal = resampler(signal)

        min_length_samples = int(MIN_LENGTH_SEC * TARGET_SR)
        if signal.shape[1] < min_length_samples:
            pad = min_length_samples - signal.shape[1]
            signal = torch.nn.functional.pad(signal, (0, pad))
        
        with torch.no_grad():
            embedding = model.encode_batch(signal)
        return embedding.squeeze().cpu().numpy()
    except Exception as e:
        print(f"x-vector ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    
def format_axis(x, pos):
    return librosa.midi_to_note(int(x))

def analyze_vocal_range(file_path, graph_save_path=None):
    
    # -----------------------
    # 1. ì •ë°€ ë¶„ì„ íŒŒë¼ë¯¸í„° ì„¤ì •
    # -----------------------
    SR = 22050           
    HOP_LENGTH = 256     
    FRAME_LENGTH = 2048  
    CONF_THRESH = 0.6    
    RMS_THRESH = 0.05    
    
    try:
        # 2. ì˜¤ë””ì˜¤ ë¡œë“œ
        y, sr = librosa.load(file_path, sr=SR)
        
        # 3. pYIN ì•Œê³ ë¦¬ì¦˜ ì‹¤í–‰
        f0, voiced_flag, voiced_probs = librosa.pyin(
            y, 
            fmin=librosa.note_to_hz('C2'), 
            fmax=librosa.note_to_hz('C7'), 
            sr=sr, 
            hop_length=HOP_LENGTH,
            frame_length=FRAME_LENGTH,
            fill_na=np.nan
        )
        
        # 4. ì—ë„ˆì§€(RMS) ê¸°ë°˜ ì¡ìŒ ì œê±°
        rms = librosa.feature.rms(y=y, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)[0]
        
        # ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ ìœ íš¨í•œ ì‹œê°„ê³¼ ì£¼íŒŒìˆ˜ ë°ì´í„°ë§Œ ì¶”ì¶œ (ê·¸ë˜í”„ìš©)
        times = librosa.times_like(f0, sr=sr, hop_length=HOP_LENGTH)

        # voiced_probs ë° rms ê¸¸ì´ ë³´ì •(ì•ˆì „ì„±)
        voiced_probs = np.asarray(voiced_probs)
        if voiced_probs.shape != f0.shape:
            voiced_probs = librosa.util.fix_length(voiced_probs, size=len(f0), fill_value=0.0)

        rms = librosa.util.fix_length(rms, size=len(f0)) 

        valid_mask = (voiced_probs > CONF_THRESH) & (rms > RMS_THRESH)

        # ì¶”ê°€ í•„í„°: f0ê°€ ìœ í•œê°’ì¸ í”„ë ˆì„ë§Œ ì‚¬ìš©
        finite_mask = np.isfinite(f0)
        final_mask = valid_mask & finite_mask

        valid_times = times[final_mask]     # ìœ íš¨í•œ ì‹œê°„ì¶•
        valid_pitches = f0[final_mask]      # ìœ íš¨í•œ ì£¼íŒŒìˆ˜(Hz)

        # ìœ íš¨í•œ ìŒì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if valid_pitches.size == 0 or valid_times.size == 0:
            print("âŒ ìœ íš¨í•œ í”¼ì¹˜ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        # Hz -> MIDI ë³€í™˜
        valid_midi = librosa.hz_to_midi(valid_pitches)

        # ì•ˆì „ì„±: ë°°ì—´ ê¸¸ì´ ì¬í™•ì¸ (plot ì˜¤ë¥˜ ë°©ì§€)
        if valid_times.shape[0] != valid_midi.shape[0]:
            minlen = min(valid_times.shape[0], valid_midi.shape[0])
            valid_times = valid_times[:minlen]
            valid_midi = valid_midi[:minlen]

        # -----------------------
        # ìˆ˜ì •: NaN/inf ì œê±° ë° ì•ˆì „í•œ percentile ê³„ì‚°
        # -----------------------
        # NaN ë˜ëŠ” inf ê°’ ì œê±°
        valid_midi = valid_midi[np.isfinite(valid_midi)]
        if valid_midi.size == 0:
            print("âŒ ìœ íš¨í•œ MIDI ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë“  ê°’ì´ NaN/inf).")
            return None, None

        try:
            # NaN ì•ˆì „ ê³„ì‚°
            min_midi = float(np.nanpercentile(valid_midi, 1))
            max_midi = float(np.nanpercentile(valid_midi, 99))
        except Exception as e:
            print(f"âŒ percentile ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
            return None, None

        # ê³„ì‚° ê²°ê³¼ê°€ ìœ í•œìˆ˜ì¸ì§€ í™•ì¸
        if not (np.isfinite(min_midi) and np.isfinite(max_midi)):
            print("âŒ ê³„ì‚°ëœ min/max MIDI ê°’ì´ ìœ í•œìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            return None, None
        # -----------------------
        
        # 7. ê²°ê³¼ ë°˜í™˜ê°’ ê³„ì‚°
        lowest_note = librosa.midi_to_note(int(round(min_midi)))
        highest_note = librosa.midi_to_note(int(round(max_midi)))
        
        print(f"   -> [ìŒì—­ëŒ€ ë¶„ì„ ì™„ë£Œ] {lowest_note} ~ {highest_note}")

        # --- [ì¶”ê°€] ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥ ë¡œì§ ---
        if graph_save_path:
            plt.figure(figsize=(12, 6)) # ê·¸ë˜í”„ í¬ê¸° ì„¤ì •
            
            # ë©”ì¸ ì‚°ì ë„ ê·¸ë¦¬ê¸° (íŒŒë€ìƒ‰ ì )
            plt.scatter(valid_times, valid_midi, s=10, c='dodgerblue', alpha=0.6, label='Detected Pitch', edgecolors='none')
            
            # ìµœì €/ìµœê³ ìŒ ê°€ì´ë“œë¼ì¸ (ì´ˆë¡/ë¹¨ê°• ì ì„ )
            plt.axhline(min_midi, color='green', linestyle='--', linewidth=2, label=f"Min: {lowest_note}")
            plt.axhline(max_midi, color='red', linestyle='--', linewidth=2, label=f"Max: {highest_note}")
            
            # Yì¶• ì„¤ì • (MIDI ìˆ«ì -> ìŒê³„ ì´ë¦„ìœ¼ë¡œ ë³€í™˜)
            y_min = int(min_midi) - 3
            y_max = int(max_midi) + 3
            plt.ylim(y_min, y_max)
            # ëª¨ë“  ë°˜ìŒ ë‹¨ìœ„ë¡œ ëˆˆê¸ˆ í‘œì‹œ
            plt.yticks(range(y_min, y_max + 1)) 
            plt.gca().yaxis.set_major_formatter(FuncFormatter(format_axis))
            
            # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ê¾¸ë¯¸ê¸°
            plt.grid(True, which='both', linestyle='-', alpha=0.3)
            plt.xlabel("Time (seconds)")
            plt.ylabel("Musical Note")
            plt.title(f"Vocal Pitch Analysis: {lowest_note} ~ {highest_note}")
            plt.legend(loc='upper right')
            plt.tight_layout()
            
            # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
            plt.savefig(graph_save_path)
            plt.close() # ë©”ëª¨ë¦¬ í•´ì œ (ì¤‘ìš”)
            print(f"   -> [ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ] {graph_save_path}")
        # -----------------------------------
        
        return lowest_note, highest_note
        
    except Exception as e:
        print(f"âŒ ìŒì—­ëŒ€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

def is_in_range(song_low, song_high, user_low, user_high, tolerance=2):
    """
    ìŒì—­ëŒ€ ë¹„êµ (tolerance: ë°˜ìŒ ë‹¨ìœ„ í—ˆìš© ì˜¤ì°¨, ê¸°ë³¸ê°’ 2)
    ì‚¬ìš©ìì˜ ìŒì—­ëŒ€ê°€ ë…¸ë˜ ìŒì—­ëŒ€ë³´ë‹¤ ì¡°ê¸ˆ ì¢ì•„ë„ í†µê³¼ì‹œí‚´
    """
    try:
        if not all([song_low, song_high, user_low, user_high]):
            return False
            
        song_low_midi = librosa.note_to_midi(song_low)
        song_high_midi = librosa.note_to_midi(song_high)
        user_low_midi = librosa.note_to_midi(user_low)
        user_high_midi = librosa.note_to_midi(user_high)
        
        # [ìˆ˜ì •] ì‚¬ìš©ìì˜ ìµœì €ìŒì´ ë…¸ë˜ë³´ë‹¤ 2í‚¤ ë†’ì•„ë„ OK (user_low - 2 <= song_low)
        #        ì‚¬ìš©ìì˜ ìµœê³ ìŒì´ ë…¸ë˜ë³´ë‹¤ 2í‚¤ ë‚®ì•„ë„ OK (user_high + 2 >= song_high)
        return (user_low_midi - tolerance) <= song_low_midi and \
               (user_high_midi + tolerance) >= song_high_midi
               
    except Exception:
        return False

def search_faiss_with_timing(index, query, k):
    """Faiss ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ê³  ë‚´ë¶€ ì‹¤í–‰ ì‹œê°„ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    search_start_time = time.time()
    scores, ids = index.search(query, k)
    search_end_time = time.time()
    # ë°€ë¦¬ì´ˆ(ms) ë‹¨ìœ„ë¡œ ì‹¤ì œ ê²€ìƒ‰ ì‹œê°„ ì¶œë ¥
    print(f"--- [ë‚´ë¶€ ì¸¡ì •] faiss.search ì‹¤ì œ ì‹¤í–‰ ì‹œê°„: {(search_end_time - search_start_time) * 1000:.4f} ms ---")
    return scores, ids


# --- 3. API ì—”ë“œí¬ì¸íŠ¸ ---
@app.get("/")
def read_root():
    return {"message": "AI ìŒì„± ë¶„ì„ ë° ë…¸ë˜ ì¶”ì²œ API"}

@app.post("/analyze")
async def analyze(
    request: Request,
    voice_file: UploadFile = File(...),
    gender: str = Form("none"),
    genre: str = Form("none"),
    start_year: int = Form(1980),
    end_year: int = Form(2025)
):
    print(f"\n========== [ë¶„ì„ ì‹œì‘] ==========")
    print(f"ğŸ“¥ ì‚¬ìš©ì ì…ë ¥ ì •ë³´: ì„±ë³„={gender}, ì¥ë¥´={genre}, ë…„ë„={start_year}~{end_year}")
    
    start_time = time.time()
    # [ìˆ˜ì • 1] singer_infoë„ í™•ì¸ ëª©ë¡ì— ì¶”ê°€
    if not all([classifier, singer_index, singer_id_map, songs_db, singer_info]):
        raise HTTPException(status_code=500, detail="ì„œë²„ ëª¨ë¸/ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    temp_file_path = f"temp_{voice_file.filename}"
    wav_file_path = temp_file_path.rsplit('.',1)[0] + ".wav"
    analysis_path = temp_file_path

    try:
        # --- íŒŒì¼ ì €ì¥ ë° ë³€í™˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
        with open(temp_file_path, "wb") as buffer:
            shutil.copyfileobj(voice_file.file, buffer)

        ext = temp_file_path.rsplit('.', 1)[-1].lower()
        if ext in ["m4a", "aac", "mp4"]:
            try:
                audio = AudioSegment.from_file(temp_file_path, format=ext)
                audio = audio.set_frame_rate(16000).set_channels(1)
                audio.export(wav_file_path, format="wav")
                analysis_path = wav_file_path
            except Exception as e:
                 print(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
                 # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš© ì‹œë„ (ì„ íƒ ì‚¬í•­)
        else:
            analysis_path = temp_file_path

        # [ì¶”ê°€] ê·¸ë˜í”„ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ìƒì„± (ìœ ë‹ˆí¬í•œ íŒŒì¼ëª… ì‚¬ìš©)
        timestamp = int(time.time())
        graph_filename = f"graph_{timestamp}.png"
        # ì‹¤ì œ ì €ì¥ë  ë¬¼ë¦¬ì  ê²½ë¡œ (backend/static/graphs/...)
        graph_save_path = os.path.join("static", "graphs", graph_filename)
    
        # --- ë¹„ë™ê¸° ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ê³¼ ë™ì¼) ---
        loop = asyncio.get_running_loop()
        xvector_task = loop.run_in_executor(None, get_xvector, analysis_path, classifier)
        vocal_range_task = loop.run_in_executor(
            None, 
            analyze_vocal_range, 
            analysis_path, 
            graph_save_path # <-- ì—¬ê¸°ì— ì¶”ê°€! (í•¨ìˆ˜ê°€ ì´ ì¸ìë¥¼ ë°›ë„ë¡ ìˆ˜ì •ë˜ì–´ ìˆì–´ì•¼ í•¨)
        )
        
        user_xvector, (user_lowest_note, user_highest_note) = await asyncio.gather(
            xvector_task,
            vocal_range_task
        )
        
        t_after_analysis = time.time()
        print(f"[Time Check] x-vector ë° ìŒì—­ëŒ€ ë™ì‹œ ë¶„ì„ ì‹œê°„: {t_after_analysis - start_time:.4f} ì´ˆ")

        if user_xvector is None:
            raise HTTPException(status_code=400, detail="ìŒì„± íŒŒì¼ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # --- Faiss ê²€ìƒ‰ ---
        user_xvector_normalized = user_xvector.astype('float32').reshape(1, -1)
        faiss.normalize_L2(user_xvector_normalized)
        k = 5 # í›„ë³´ë¥¼ ë„‰ë„‰í•˜ê²Œ 5ëª… ì •ë„ ë½‘ìŠµë‹ˆë‹¤
        scores, ids = singer_index.search(user_xvector_normalized, k)
        
        # [ìˆ˜ì • 2] raw_top_k ì •ì˜ (í•„í„°ë§ì„ ìœ„í•œ ì›ë³¸ ë°ì´í„°)
        raw_top_k = []
        for i in range(k):
            singer_id = ids[0][i]
            if singer_id != -1:
                raw_top_k.append({
                    "singer": singer_id_map[singer_id],
                    "similarity": float(scores[0][i]) * 100 # ìˆ«ìí˜•ìœ¼ë¡œ ì €ì¥
                })

        # --- í•„í„°ë§ ë¡œì§ ---
        
        # 1. ì„±ë³„ í•„í„°ë§
        filtered_artists = []
        if gender == 'none':
            filtered_artists = [res['singer'] for res in raw_top_k]
        else:
            for res in raw_top_k:
                artist_name = res['singer']
                # singer_infoì— ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¼ë‹¨ í¬í•¨í•˜ê±°ë‚˜ ì œì™¸ (ì—¬ê¸°ì„  í¬í•¨ìœ¼ë¡œ ê°€ì •)
                if singer_info.get(artist_name) == gender:
                    filtered_artists.append(artist_name)
        
        # ë§Œì•½ ì„±ë³„ í•„í„°ë§ í›„ ë‚¨ì€ ê°€ìˆ˜ê°€ ì—†ìœ¼ë©´, ì›ë˜ Top K ê·¸ëŒ€ë¡œ ì‚¬ìš© (Fallback)
        if not filtered_artists:
             filtered_artists = [res['singer'] for res in raw_top_k]

        # 2. ìµœì¢… ë…¸ë˜ ì¶”ì²œ (ì¥ë¥´, ë…„ë„, ìŒì—­ëŒ€)
        recommended_songs = []
        best_match_singer = filtered_artists[0] if filtered_artists else "N/A"
        target_gtzan_genres = USER_TO_GTZAN_MAP.get(genre, []) # ìƒë‹¨ì— ì •ì˜ëœ MAP ì‚¬ìš©

        # í•„í„°ë§ëœ ê°€ìˆ˜ ëª©ë¡ì„ ìˆœíšŒí•˜ë©° ì¡°ê±´ì— ë§ëŠ” ë…¸ë˜ ì°¾ê¸°
        for artist_name in filtered_artists:
            if recommended_songs: # ì´ë¯¸ ì¶”ì²œê³¡ì„ ì°¾ì•˜ë‹¤ë©´ ë£¨í”„ ì¤‘ë‹¨
                break
                
            singer_song_list = songs_db.get(artist_name, [])
            
            for song in singer_song_list:
                song_year = song.get('year')
                # API ì¥ë¥´ì™€ ëª¨ë¸ ì˜ˆì¸¡ ì¥ë¥´ ëª¨ë‘ í™•ì¸
                song_genres = song.get('genres_api', []) + song.get('genres_model', [])

                # A. ë…„ë„ í•„í„°
                if song_year and not (start_year <= song_year <= end_year):
                    continue
                # B. ì¥ë¥´ í•„í„° (êµì§‘í•© í™•ì¸)
                if genre != 'none' and not any(g in target_gtzan_genres for g in song_genres):
                    continue
                # C. ìŒì—­ëŒ€ í•„í„°
                if is_in_range(song['lowest_note'], song['highest_note'], user_lowest_note, user_highest_note):
                    recommended_songs.append(song['title'])
        
        # [ì¤‘ìš”] ìœ„ì—ì„œ êµ¬í•œ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•´ì•¼ í•¨ (ë®ì–´ì“°ê¸° ì½”ë“œ ì‚­ì œë¨)
        graph_url = f"{str(request.base_url).rstrip('/')}/static/graphs/{graph_filename}"
        print(f"DEBUG: pitch_graph_url -> {graph_url}")

        user_range_str = f"{user_lowest_note} ~ {user_highest_note}" if user_lowest_note else "ë¶„ì„ ë¶ˆê°€"
        
        end_time = time.time()
        print(f"[Time Check] ì´ API ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.4f} ì´ˆ")

        # ë°˜í™˜ê°’ ìƒì„±
        return {
            "best_match": best_match_singer,
            "user_vocal_range": user_range_str,
            "recommended_songs": recommended_songs,
            "pitch_graph_url": graph_url, # <-- [í•µì‹¬] ê·¸ë˜í”„ URL ì¶”ê°€
            # í”„ë¡ íŠ¸ì—”ë“œ í‘œì‹œìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜
            "top_k_results": [
                {"singer": res['singer'], "similarity": f"{res['similarity']:.2f}%"} 
                for res in raw_top_k
            ],
        }
    finally:
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        # ë³€í™˜ëœ íŒŒì¼ë„ ì‚­ì œí•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
        # if os.path.exists(wav_file_path) and analysis_path != temp_file_path:
        #     os.remove(wav_file_path)