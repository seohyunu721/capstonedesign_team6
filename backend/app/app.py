import os
import shutil
import glob
import numpy as np
import joblib
import torch
import torchaudio
import faiss
import librosa
import json
import time  
import asyncio
# ì¶”ê°€ ë³¸ ###################
import soundfile as sf
from pydub import AudioSegment
#########################
from fastapi import FastAPI, UploadFile, File, HTTPException,Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.concurrency import run_in_threadpool
from speechbrain.inference import EncoderClassifier
from torchaudio.transforms import Resample

# --- 1. FastAPI ì•± ë° ëª¨ë¸ ë¡œë”© ---
app = FastAPI()

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
USER_TO_GTZAN_MAP = {
    "ë°œë¼ë“œ": ["pop", "classical", "jazz", "blues", "k-ballad"], 
    "ëŒ„ìŠ¤": ["disco", "pop", "hiphop", "k-pop", "dance-pop"], 
    "R&B": ["hiphop", "jazz", "pop", "r&b", "soul"],
    "ë¡": ["rock", "metal", "k-rock"],
    "ë©/í™í•©": ["hiphop", "rap", "k-rap"],
    "íŒ": ["pop", "disco", "k-pop"]
}

# ëª¨ë¸ ë¡œë“œ [spkrec-ecapa-voxceleb] ECAPA ì‚¬ìš©
model = EncoderClassifier.from_hparams(
    source="speechbrain/spkrec-ecapa-voxceleb",
    run_opts={"device":"cuda" if torch.cuda.is_available() else "cpu"}
# ì €ì¥ dir ì§€ìš¸ ê°€ëŠ¥ì„± ìˆìŒ
)

APP_DIR = os.path.dirname(os.path.abspath(__file__))
BACKEND_DIR = os.path.dirname(APP_DIR)
MODELS_DIR = os.path.join(BACKEND_DIR, 'models')
DATA_DIR = os.path.join(BACKEND_DIR, 'data')

try:
    print("ëª¨ë¸/ë°ì´í„° ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    classifier = EncoderClassifier.from_hparams(
        source="speechbrain/spkrec-ecapa-voxceleb",
        run_opts={"device":"cuda" if torch.cuda.is_available() else "cpu"}
    )    
        
    singer_index = faiss.read_index(os.path.join(MODELS_DIR, "singers.index"))
    singer_id_map = joblib.load(os.path.join(MODELS_DIR, "singer_id_map.pkl"))
    
    with open(os.path.join(DATA_DIR, "songs_db.json"), 'r', encoding='utf-8') as f:
        songs_db = json.load(f)
        
    with open(os.path.join(DATA_DIR, "singer_info.json"), 'r', encoding='utf-8') as f:
        singer_info = json.load(f)
    
    print("ëª¨ë“  ëª¨ë¸ ë° ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
except Exception as e:
    print(f"ëª¨ë¸/ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    classifier, singer_index, singer_id_map, songs_db = None, None, None, None

# --- 2. í•µì‹¬ ë¶„ì„ í•¨ìˆ˜ë“¤ ---
from pydub import AudioSegment

def convert_to_wav(aac_path, wav_file_path):
    audio = AudioSegment.from_file(aac_path, format="aac")
    audio = audio.set_frame_rate(16000).set_channels(1)
    audio.export(wav_file_path, format="wav")
    return wav_file_path




# ë…¹ìŒ íŒŒì¼ ì•ˆì „í•˜ê²Œ ë¡œë”©ë˜ê²Œ 
def safe_load_audio(file_path, target_sr=16000, mono=True):
    try:
        # librosaê°€ wav í—¤ë” ê¹¨ì§„ ê²ƒë„ ìë™ ë³µì›
        y, sr = librosa.load(file_path, sr=target_sr) # mono=True
        # ë¬´ìŒ ë°©ì§€ìš© ì•„ì£¼ ì‘ì€ ë…¸ì´ì¦ˆ ì¶”ê°€
        if np.max(np.abs(y)) < 1e-5:
            y = y + np.random.randn(len(y)) * 1e-5
        return y, target_sr
    except Exception as e:
        print(f"[Audio Load Error] {e}")
        data, sr = sf.read(file_path)
        return data.astype(np.float32), sr



def extract_xvector(file_path):
    signal, sr = sf.read(file_path)
    # ìµœì†Œ ê¸¸ì´ ì²´í¬
    if len(signal) < sr * 0.5:  # 0.5ì´ˆ ë¯¸ë§Œ
        raise ValueError("Audio too short for x-vector extraction")
    return classifier.encode_file(file_path)


def get_xvector(file_path, model):
    TARGET_SR = 16000
    MIN_LENGTH_SEC = 0.5
    try:
        signal, fs = torchaudio.load(file_path)
        if signal.shape[0] > 1:
            signal = torch.mean(signal, dim=0, keepdim=True)
        if fs != TARGET_SR:
            resampler = Resample(orig_freq=fs, new_freq=TARGET_SR)
            signal = resampler(signal)

        min_length_samples = int(MIN_LENGTH_SEC * TARGET_SR)
        if signal.shape[1] < min_length_samples:
            pad = min_length_samples - signal.shape[1]
            signal = torch.nn.functional.pad(signal, (0, pad))
        
        with torch.no_grad():
            embedding = model.encode_batch(signal)
        return embedding.squeeze().cpu().numpy()
    except Exception as e:
        print(f"x-vector ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def analyze_vocal_range(file_path):
    """librosa.pyinì„ ì‚¬ìš©í•´ ë” ì •í™•í•˜ê²Œ ìŒì—­ëŒ€ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""
    try:
        y, sr = librosa.load(file_path, sr=16000)

        # ë…¸ì´ì¦ˆ ì¤„ì´ëŠ” ì½”ë“œ (ì§§ì€ ë¬´ìŒ êµ¬ê°„ ì œê±°)
        y, _ = librosa.effects.trim(y, top_db=30)

        rms = np.sqrt(np.mean(y**2))
        
        if len(y) < sr * 0.5:
            print(f"[ê²½ê³ ] {file_path} ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŒ")
            return None, None
        
       
        if rms < 0.005:
            print(f"[ê²½ê³ ] {file_path} ìŒëŸ‰ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ (rms={rms:.4f})")
            return None, None

        
        
        # 1. pYIN ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê¸°ë³¸ ì£¼íŒŒìˆ˜(F0) ì¶”ì •
        # fmin/fmaxë¡œ ì‚¬ëŒ ëª©ì†Œë¦¬ì˜ í•©ë¦¬ì ì¸ ë²”ìœ„ë§Œ íƒìƒ‰í•˜ë„ë¡ ì œí•œ
        f0, voiced_flag, voiced_probs = librosa.pyin(
            y,
            sr=sr,
            fmin=librosa.note_to_hz('A1'),  # 55Hz
            fmax=librosa.note_to_hz('C8'), 
            # fmin=librosa.note_to_hz('C2'), # ìµœì €ìŒ (ì•½ 65Hz)
            # fmax=librosa.note_to_hz('C7'),
            frame_length=2048,
            hop_length=512  # ìµœê³ ìŒ (ì•½ 2093Hz)
        )
        
        # 2. 'ë…¸ë˜ê°€ ë¶ˆë¦° êµ¬ê°„(voiced)'ì˜ ìœ íš¨í•œ ìŒë†’ì´ ê°’ë§Œ ì¶”ì¶œ
        valid_pitches = f0[voiced_flag]

        if valid_pitches is None or valid_pitches.size == 0:
            return None, None
            
        # 3. NaN ê°’ ì œê±° (pYIN ê²°ê³¼ì— í¬í•¨ë  ìˆ˜ ìˆìŒ)
        valid_pitches = valid_pitches[~np.isnan(valid_pitches)]
        
        if valid_pitches.size == 0:
            return None, None

        # 4. ë°±ë¶„ìœ„ìˆ˜ë¥¼ ì‚¬ìš©í•´ ê·¹ë‹¨ì ì¸ ì•„ì›ƒë¼ì´ì–´ ê°’ ì œê±°
        min_freq = np.percentile(valid_pitches, 5)  # í•˜ìœ„ 5%
        max_freq = np.percentile(valid_pitches, 95) # ìƒìœ„ 95%
        
        lowest_note = librosa.hz_to_note(min_freq)
        highest_note = librosa.hz_to_note(max_freq)
        
        return lowest_note, highest_note
        
    except Exception as e:
        print(f"'{os.path.basename(file_path)}' ìŒì—­ëŒ€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return None, None
    



def is_in_range(song_low, song_high, user_low, user_high):
    try:
        return librosa.note_to_midi(user_low) <= librosa.note_to_midi(song_low) and librosa.note_to_midi(user_high) >= librosa.note_to_midi(song_high)
    except Exception:
        return False

def search_faiss_with_timing(index, query, k):
    """Faiss ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ê³  ë‚´ë¶€ ì‹¤í–‰ ì‹œê°„ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜"""
    search_start_time = time.time()
    scores, ids = index.search(query, k)
    search_end_time = time.time()
    # ë°€ë¦¬ì´ˆ(ms) ë‹¨ìœ„ë¡œ ì‹¤ì œ ê²€ìƒ‰ ì‹œê°„ ì¶œë ¥
    print(f"--- [ë‚´ë¶€ ì¸¡ì •] faiss.search ì‹¤ì œ ì‹¤í–‰ ì‹œê°„: {(search_end_time - search_start_time) * 1000:.4f} ms ---")
    return scores, ids


# --- 3. API ì—”ë“œí¬ì¸íŠ¸ ---
@app.get("/")
def read_root():
    return {"message": "AI ìŒì„± ë¶„ì„ ë° ë…¸ë˜ ì¶”ì²œ API"}

@app.post("/analyze")
async def analyze(
    voice_file: UploadFile = File(...),
    gender: str = Form("none"),
    genre: str = Form("none"),
    start_year: int = Form(1980),
    end_year: int = Form(2025)
):
    print(f"\n========== [ë¶„ì„ ì‹œì‘] ==========")
    print(f"ğŸ“¥ ì‚¬ìš©ì ì…ë ¥ ì •ë³´: ì„±ë³„={gender}, ì¥ë¥´={genre}, ë…„ë„={start_year}~{end_year}")
    
    start_time = time.time()
    # [ìˆ˜ì • 1] singer_infoë„ í™•ì¸ ëª©ë¡ì— ì¶”ê°€
    if not all([classifier, singer_index, singer_id_map, songs_db, singer_info]):
        raise HTTPException(status_code=500, detail="ì„œë²„ ëª¨ë¸/ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    temp_file_path = f"temp_{voice_file.filename}"
    wav_file_path = temp_file_path.rsplit('.',1)[0] + ".wav"
    analysis_path = temp_file_path

    try:
        # --- íŒŒì¼ ì €ì¥ ë° ë³€í™˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
        with open(temp_file_path, "wb") as buffer:
            shutil.copyfileobj(voice_file.file, buffer)

        ext = temp_file_path.rsplit('.', 1)[-1].lower()
        if ext in ["m4a", "aac", "mp4"]:
            try:
                audio = AudioSegment.from_file(temp_file_path, format=ext)
                audio = audio.set_frame_rate(16000).set_channels(1)
                audio.export(wav_file_path, format="wav")
                analysis_path = wav_file_path
            except Exception as e:
                 print(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
                 # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš© ì‹œë„ (ì„ íƒ ì‚¬í•­)
        else:
            analysis_path = temp_file_path

        # --- ë¹„ë™ê¸° ë¶„ì„ ì‹¤í–‰ (ê¸°ì¡´ê³¼ ë™ì¼) ---
        loop = asyncio.get_running_loop()
        xvector_task = loop.run_in_executor(None, get_xvector, analysis_path, classifier)
        vocal_range_task = loop.run_in_executor(None, analyze_vocal_range, analysis_path)

        user_xvector, (user_lowest_note, user_highest_note) = await asyncio.gather(
            xvector_task,
            vocal_range_task
        )
        
        t_after_analysis = time.time()
        print(f"[Time Check] x-vector ë° ìŒì—­ëŒ€ ë™ì‹œ ë¶„ì„ ì‹œê°„: {t_after_analysis - start_time:.4f} ì´ˆ")

        if user_xvector is None:
            raise HTTPException(status_code=400, detail="ìŒì„± íŒŒì¼ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # --- Faiss ê²€ìƒ‰ ---
        user_xvector_normalized = user_xvector.astype('float32').reshape(1, -1)
        faiss.normalize_L2(user_xvector_normalized)
        k = 5 # í›„ë³´ë¥¼ ë„‰ë„‰í•˜ê²Œ 5ëª… ì •ë„ ë½‘ìŠµë‹ˆë‹¤
        scores, ids = singer_index.search(user_xvector_normalized, k)
        
        # [ìˆ˜ì • 2] raw_top_k ì •ì˜ (í•„í„°ë§ì„ ìœ„í•œ ì›ë³¸ ë°ì´í„°)
        raw_top_k = []
        for i in range(k):
            singer_id = ids[0][i]
            if singer_id != -1:
                raw_top_k.append({
                    "singer": singer_id_map[singer_id],
                    "similarity": float(scores[0][i]) * 100 # ìˆ«ìí˜•ìœ¼ë¡œ ì €ì¥
                })

        # --- í•„í„°ë§ ë¡œì§ ---
        
        # 1. ì„±ë³„ í•„í„°ë§
        filtered_artists = []
        if gender == 'none':
            filtered_artists = [res['singer'] for res in raw_top_k]
        else:
            for res in raw_top_k:
                artist_name = res['singer']
                # singer_infoì— ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¼ë‹¨ í¬í•¨í•˜ê±°ë‚˜ ì œì™¸ (ì—¬ê¸°ì„  í¬í•¨ìœ¼ë¡œ ê°€ì •)
                if singer_info.get(artist_name) == gender:
                    filtered_artists.append(artist_name)
        
        # ë§Œì•½ ì„±ë³„ í•„í„°ë§ í›„ ë‚¨ì€ ê°€ìˆ˜ê°€ ì—†ìœ¼ë©´, ì›ë˜ Top K ê·¸ëŒ€ë¡œ ì‚¬ìš© (Fallback)
        if not filtered_artists:
             filtered_artists = [res['singer'] for res in raw_top_k]

        # 2. ìµœì¢… ë…¸ë˜ ì¶”ì²œ (ì¥ë¥´, ë…„ë„, ìŒì—­ëŒ€)
        recommended_songs = []
        best_match_singer = filtered_artists[0] if filtered_artists else "N/A"
        target_gtzan_genres = USER_TO_GTZAN_MAP.get(genre, []) # ìƒë‹¨ì— ì •ì˜ëœ MAP ì‚¬ìš©

        # í•„í„°ë§ëœ ê°€ìˆ˜ ëª©ë¡ì„ ìˆœíšŒí•˜ë©° ì¡°ê±´ì— ë§ëŠ” ë…¸ë˜ ì°¾ê¸°
        for artist_name in filtered_artists:
            if recommended_songs: # ì´ë¯¸ ì¶”ì²œê³¡ì„ ì°¾ì•˜ë‹¤ë©´ ë£¨í”„ ì¤‘ë‹¨
                break
                
            singer_song_list = songs_db.get(artist_name, [])
            
            for song in singer_song_list:
                song_year = song.get('year')
                # API ì¥ë¥´ì™€ ëª¨ë¸ ì˜ˆì¸¡ ì¥ë¥´ ëª¨ë‘ í™•ì¸
                song_genres = song.get('genres_api', []) + song.get('genres_model', [])

                # A. ë…„ë„ í•„í„°
                if song_year and not (start_year <= song_year <= end_year):
                    continue
                # B. ì¥ë¥´ í•„í„° (êµì§‘í•© í™•ì¸)
                if genre != 'none' and not any(g in target_gtzan_genres for g in song_genres):
                    continue
                # C. ìŒì—­ëŒ€ í•„í„°
                if is_in_range(song['lowest_note'], song['highest_note'], user_lowest_note, user_highest_note):
                    recommended_songs.append(song['title'])
        
        # [ì¤‘ìš”] ìœ„ì—ì„œ êµ¬í•œ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•´ì•¼ í•¨ (ë®ì–´ì“°ê¸° ì½”ë“œ ì‚­ì œë¨)
        
        user_range_str = f"{user_lowest_note} ~ {user_highest_note}" if user_lowest_note else "ë¶„ì„ ë¶ˆê°€"
        
        end_time = time.time()
        print(f"[Time Check] ì´ API ì²˜ë¦¬ ì‹œê°„: {end_time - start_time:.4f} ì´ˆ")

        # ë°˜í™˜ê°’ ìƒì„±
        return {
            "best_match": best_match_singer,
            "user_vocal_range": user_range_str,
            "recommended_songs": recommended_songs,
            # í”„ë¡ íŠ¸ì—”ë“œ í‘œì‹œìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜
            "top_k_results": [
                {"singer": res['singer'], "similarity": f"{res['similarity']:.2f}%"} 
                for res in raw_top_k
            ],
        }
    finally:
        if os.path.exists(temp_file_path):
            os.remove(temp_file_path)
        # ë³€í™˜ëœ íŒŒì¼ë„ ì‚­ì œí•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
        # if os.path.exists(wav_file_path) and analysis_path != temp_file_path:
        #     os.remove(wav_file_path)